{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes: Difference on probability vs statistics\n",
    "\n",
    "In probability we compute the probability of data arising from a parametric model with known parameters. \n",
    "\n",
    "In statistics we will estimate the probability of parameters given a parametric model and observed data drawn from it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. What is maximum likelihood estimates (MLE)?\n",
    "\n",
    "MLE finds the answer of for which parameter value does the observed data have the biggest probability. THe MLE is an example of a point estimate because it gives a single value for the unknown parameter. \n",
    "\n",
    "The idea for the maximum likelihood estimate is to find the value of the parameter(s) for which the data has the highest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q. Why we use the density to find the MLE for continuous distributions?\n",
    "\n",
    "We will do this by considering a smaller version of the light blub example.\n",
    "\n",
    "Suppose we have two light bulbs whose lifetimes follow an exponential $(\\lambda) $ distribution. Suppose also that we independently measure their lifetimes and get data $x_1 $= 2 years and $x_2 $= 3 years. Find the value of $ \\lambda $ that maximizes the probability of this data.\n",
    "\n",
    "The main paradox to deal with is that for a continuous distribution the probability of a single value, say $x_1$=2, is zero. We resolve this paradox by remembering that a single measurement really means a range of values, e.g. in this example we might check the light bulb once a day. So the data $x_1$ = 2 years really means $x_1$ is somewhere in a range of 1 day around 2 years.\n",
    "\n",
    "If the range is small we call it $dx_1$. The probability that $X_1$ is in the range is approximated by $f(x_1|\\lambda)dx_1$. The data value $x_2$ is treated in exactly the same way. \n",
    "\n",
    "Since the data is collected independently,\n",
    "\n",
    "$ P(X_1, X_2|\\lambda) = f(x_1|\\lambda)dx_1 f(x_2|\\lambda)dx_2$\n",
    "\n",
    "Using the values $x_1$ = 2 and $x_2$ = 3 we get,\n",
    "\n",
    "$ P(X_1, X_2|\\lambda) = \\lambda e^{-2\\lambda}dx_1.\\lambda e^{-3\\lambda}dx_2 = \\lambda ^2 e^{-5\\lambda} dx_1dx_2 $\n",
    "\n",
    "Now that we have a genuine probability we can look for the value of $ \\lambda $ that maximizes it. Looking at the formula above we see that the factor $dx_1 dx_2$ will play no role in finding the maximum. So for the MLE we drop it and simply call the density the likelihood:\n",
    "\n",
    "$ likelihood = f(x_1, x_2|\\lambda) = \\lambda ^2 e^{-5\\lambda} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
